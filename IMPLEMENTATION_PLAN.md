# MCPé¡¹ç›® - å‰©ä½™é˜¶æ®µå®æ–½æ–¹æ¡ˆ

> **æ–‡æ¡£ç›®çš„**: è¯¦ç»†è§„åˆ’Phase 3-9çš„å®ç°æ­¥éª¤ã€ä»£ç ç»“æ„ã€å…³é”®æŠ€æœ¯ç‚¹

---

## ğŸ¯ Phase 3: è®°å¿†ç®¡ç†æœåŠ¡å®ç°

### 3.1 Rediså®¢æˆ·ç«¯å°è£…

**æ–‡ä»¶**: `src/mcp_core/services/redis_client.py`

**æ ¸å¿ƒåŠŸèƒ½**:
```python
class RedisClient:
    def __init__(self, config: RedisSettings):
        """åˆå§‹åŒ–Redisè¿æ¥æ± """
        self.pool = redis.ConnectionPool.from_url(...)
        self.client = redis.Redis(connection_pool=self.pool)

    # çŸ­æœŸè®°å¿†æ“ä½œ
    def store_short_memory(self, project_id, memory_data, score):
        """ZADDå­˜å‚¨,æŒ‰relevance_scoreæ’åº"""
        key = f"project:{project_id}:short_mem"
        self.client.zadd(key, {json.dumps(memory_data): score})
        self.client.expire(key, ttl)

    def get_short_memories(self, project_id, top_k):
        """ZREVRANGEæ£€ç´¢Top-K"""
        return self.client.zrevrange(key, 0, top_k-1, withscores=True)

    # ç¼“å­˜æ“ä½œ
    def cache_retrieval(self, cache_key, data, ttl):
        """SETEXç¼“å­˜æ£€ç´¢ç»“æœ"""
        self.client.setex(cache_key, ttl, json.dumps(data))

    def get_cached(self, cache_key):
        """GETè·å–ç¼“å­˜"""
        return json.loads(self.client.get(cache_key) or "{}")
```

**æŠ€æœ¯è¦ç‚¹**:
- ä½¿ç”¨è¿æ¥æ± é¿å…é¢‘ç¹åˆ›å»ºè¿æ¥
- æœ‰åºé›†åˆ(ZSET)å®ç°æŒ‰åˆ†æ•°æ’åº
- TTLè‡ªåŠ¨è¿‡æœŸ(24å°æ—¶)
- pipelineæ‰¹é‡æ“ä½œæå‡æ€§èƒ½

---

### 3.2 Milvuså‘é‡æ•°æ®åº“å°è£…

**æ–‡ä»¶**: `src/mcp_core/services/vector_db.py`

**Collection Schema**:
```python
COLLECTION_SCHEMA = {
    "mid_term_memories": {
        "fields": [
            {"name": "memory_id", "type": "VarChar", "max_length": 64, "is_primary": True},
            {"name": "project_id", "type": "VarChar", "max_length": 64},
            {"name": "embedding", "type": "FloatVector", "dim": 768},
            {"name": "content", "type": "VarChar", "max_length": 2000},
            {"name": "category", "type": "VarChar", "max_length": 50},
            {"name": "created_at", "type": "Int64"},
        ],
        "index": {
            "field": "embedding",
            "index_type": "HNSW",
            "metric_type": "COSINE",
            "params": {"M": 16, "efConstruction": 200}
        }
    }
}

class VectorDBClient:
    def create_collection(self, collection_name):
        """åˆ›å»ºCollection(é¦–æ¬¡å¯åŠ¨æ—¶)"""
        schema = CollectionSchema(fields=..., description=...)
        collection = Collection(name, schema)
        collection.create_index(...)

    def insert_vectors(self, collection_name, vectors_data):
        """æ‰¹é‡æ’å…¥å‘é‡"""
        collection.insert(vectors_data)
        collection.flush()  # ç¡®ä¿æŒä¹…åŒ–

    def search_vectors(self, collection_name, query_vector, top_k, filter_expr):
        """å‘é‡æ£€ç´¢"""
        search_params = {"metric_type": "COSINE", "params": {"ef": 64}}
        results = collection.search(
            data=[query_vector],
            anns_field="embedding",
            param=search_params,
            limit=top_k,
            expr=filter_expr  # ä¾‹å¦‚: f"project_id == '{project_id}'"
        )
        return results
```

**æŠ€æœ¯è¦ç‚¹**:
- HNSWç´¢å¼•(é«˜æ€§èƒ½è¿‘ä¼¼æ£€ç´¢)
- COSINEä½™å¼¦ç›¸ä¼¼åº¦
- è¿‡æ»¤è¡¨è¾¾å¼å®ç°é¡¹ç›®éš”ç¦»
- å®šæœŸflushç¡®ä¿æ•°æ®æŒä¹…åŒ–

---

### 3.3 åµŒå…¥ç”ŸæˆæœåŠ¡

**æ–‡ä»¶**: `src/mcp_core/services/embedding_service.py`

```python
from sentence_transformers import SentenceTransformer
import torch

class EmbeddingService:
    def __init__(self, model_name: str = "all-MiniLM-L6-v2"):
        """åˆå§‹åŒ–æ¨¡å‹(å•ä¾‹)"""
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.model = SentenceTransformer(model_name, device=self.device)
        self.dimension = self.model.get_sentence_embedding_dimension()  # 384

    def encode_single(self, text: str) -> List[float]:
        """ç”Ÿæˆå•æ¡åµŒå…¥"""
        return self.model.encode(text, convert_to_numpy=True).tolist()

    def encode_batch(self, texts: List[str], batch_size: int = 32) -> List[List[float]]:
        """æ‰¹é‡ç”ŸæˆåµŒå…¥(æ€§èƒ½ä¼˜åŒ–)"""
        embeddings = self.model.encode(
            texts,
            batch_size=batch_size,
            show_progress_bar=False,
            convert_to_numpy=True
        )
        return embeddings.tolist()

    @lru_cache(maxsize=1000)
    def encode_cached(self, text: str) -> tuple:
        """å¸¦ç¼“å­˜çš„åµŒå…¥ç”Ÿæˆ(å¸¸ç”¨æ–‡æœ¬)"""
        return tuple(self.encode_single(text))
```

**æ€§èƒ½ä¼˜åŒ–**:
- GPUåŠ é€Ÿ(å¦‚æœå¯ç”¨)
- æ‰¹é‡å¤„ç†å‡å°‘æ¨¡å‹è°ƒç”¨
- LRUç¼“å­˜å¸¸ç”¨æ–‡æœ¬(èŠ‚çœ90%è®¡ç®—)

---

### 3.4 è®°å¿†ç®¡ç†æ ¸å¿ƒæœåŠ¡

**æ–‡ä»¶**: `src/mcp_core/services/memory_service.py` (å®Œæ•´å®ç°)

**ç±»ç»“æ„**:
```python
class MemoryService:
    def __init__(self):
        self.redis_client = RedisClient(...)
        self.vector_db = VectorDBClient(...)
        self.embedding_service = EmbeddingService(...)
        self.db_session = SessionLocal()

    # ========== å­˜å‚¨è®°å¿† ==========
    def store_memory(self, project_id, content, memory_level, metadata):
        """
        æ ¸å¿ƒé€»è¾‘:
        1. æå–æ ¸å¿ƒä¿¡æ¯(å»é™¤å†—ä½™)
        2. è®¡ç®—ç›¸å…³æ€§è¯„åˆ†
        3. æ ¹æ®å±‚çº§å­˜å‚¨:
           - short: Redis ZADD
           - mid: Milvus insert + embedding
           - long: PostgreSQL insert
        4. è¿”å›memory_id
        """
        memory_id = generate_id("mem")

        if memory_level == "short":
            self.redis_client.store_short_memory(...)
        elif memory_level == "mid":
            embedding = self.embedding_service.encode_single(content)
            self.vector_db.insert_vectors(...)
        else:
            long_mem = LongMemory(...)
            self.db_session.add(long_mem)

        return {"memory_id": memory_id, "stored_at": ...}

    # ========== æ£€ç´¢è®°å¿† ==========
    def retrieve_memory(self, project_id, query, top_k, memory_levels):
        """
        æ ¸å¿ƒé€»è¾‘:
        1. ç”ŸæˆqueryåµŒå…¥
        2. å¹¶è¡Œæ£€ç´¢ä¸‰ä¸ªå±‚çº§:
           - short: Redis ZREVRANGE
           - mid: Milvus search
           - long: PostgreSQL query
        3. åˆå¹¶ç»“æœå¹¶å»é‡
        4. æŒ‰relevance_scoreæ’åº
        5. è¿”å›Top-K + tokenèŠ‚çœé‡
        """
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"retrieve:{hash(project_id + query)}"
        cached = self.redis_client.get_cached(cache_key)
        if cached:
            return cached

        # ç”ŸæˆåµŒå…¥
        query_embedding = self.embedding_service.encode_single(query)

        # å¹¶è¡Œæ£€ç´¢
        all_memories = []

        if "short" in memory_levels:
            short_mems = self.redis_client.get_short_memories(project_id, top_k)
            all_memories.extend(...)

        if "mid" in memory_levels:
            mid_results = self.vector_db.search_vectors(
                "mid_term_memories",
                query_embedding,
                top_k,
                filter_expr=f"project_id == '{project_id}'"
            )
            all_memories.extend(...)

        if "long" in memory_levels:
            long_mems = self.db_session.query(LongMemory).filter(...)
            all_memories.extend(...)

        # å»é‡+æ’åº
        unique = self._deduplicate(all_memories)
        sorted_mems = sorted(unique, key=lambda x: x["relevance_score"], reverse=True)[:top_k]

        # ç¼“å­˜ç»“æœ
        result = {"memories": sorted_mems, "total_token_saved": ...}
        self.redis_client.cache_retrieval(cache_key, result, ttl=604800)

        return result

    # ========== æ›´æ–°è®°å¿† ==========
    def update_memory(self, memory_id, new_content, metadata):
        """
        å†²çªè§£å†³ç­–ç•¥:
        1. æ£€æŸ¥ç½®ä¿¡åº¦(é«˜è¦†ç›–ä½)
        2. æ£€æŸ¥æ—¶é—´(æ–°è¦†ç›–æ—§)
        3. è®°å½•æ›´æ–°å†å²(audit_log)
        """
        pass

    # ========== åˆ é™¤è®°å¿† ==========
    def delete_memory(self, memory_id, memory_level):
        """è½¯åˆ é™¤+å®¡è®¡æ—¥å¿—"""
        pass

    # ========== è¾…åŠ©æ–¹æ³• ==========
    def _deduplicate(self, memories):
        """åŸºäºcontent hashå»é‡"""
        seen_hashes = set()
        unique = []
        for mem in memories:
            content_hash = hash_content(mem["content"])
            if content_hash not in seen_hashes:
                seen_hashes.add(content_hash)
                unique.append(mem)
        return unique
```

**å…³é”®æŠ€æœ¯ç‚¹**:
1. **ä¸‰çº§å­˜å‚¨éš”ç¦»**: Redis(çƒ­æ•°æ®)/Milvus(è¯­ä¹‰æ£€ç´¢)/PostgreSQL(æ ¸å¿ƒäº‹å®)
2. **å¹¶è¡Œæ£€ç´¢**: ä¸‰ä¸ªæ•°æ®æºåŒæ—¶æŸ¥è¯¢,æœ€ç»ˆåˆå¹¶
3. **æ™ºèƒ½ç¼“å­˜**: æ£€ç´¢ç»“æœç¼“å­˜7å¤©,ç›¸åŒqueryç›´æ¥è¿”å›
4. **å»é‡æœºåˆ¶**: content hash + memory_idåŒé‡å»é‡
5. **å†²çªè§£å†³**: ç½®ä¿¡åº¦ä¼˜å…ˆ,æ—¶é—´æ¬¡ä¼˜,äººå·¥å…œåº•

---

## ğŸ¯ Phase 4: Tokenä¼˜åŒ–æœåŠ¡å®ç°

### æ–‡ä»¶ç»“æ„
```
src/mcp_core/services/
â”œâ”€â”€ token_service.py         # ä¸»æœåŠ¡
â”œâ”€â”€ compressors/
â”‚   â”œâ”€â”€ code_compressor.py   # ä»£ç å‹ç¼©(CodeBERT)
â”‚   â””â”€â”€ text_compressor.py   # æ–‡æœ¬å‹ç¼©(TextRank)
```

### æ ¸å¿ƒå®ç°

**`token_service.py`**:
```python
class TokenOptimizationService:
    def compress_content(self, content, content_type, compression_ratio):
        """
        å‹ç¼©æµç¨‹:
        1. æ£€æŸ¥ç¼“å­˜(hash(content))
        2. åˆ¤æ–­å†…å®¹ç±»å‹
        3. è°ƒç”¨å¯¹åº”å‹ç¼©å™¨:
           - code: CodeBERTæå–æ ¸å¿ƒé€»è¾‘
           - text: TextRankæ‘˜è¦
        4. è®¡ç®—TokenèŠ‚çœé‡
        5. ç¼“å­˜ç»“æœ
        """
        # Tokenè®¡ç®—(ç²—ç•¥ä¼°ç®—: 1 token â‰ˆ 4å­—ç¬¦)
        original_tokens = len(content) // 4

        if content_type == "code":
            compressed = self._compress_code(content, compression_ratio)
        else:
            compressed = self._compress_text(content, compression_ratio)

        compressed_tokens = len(compressed) // 4

        return {
            "original_tokens": original_tokens,
            "compressed_tokens": compressed_tokens,
            "compression_rate": 1 - (compressed_tokens / original_tokens),
            "compressed_content": compressed
        }

    def _compress_code(self, code, ratio):
        """
        ä»£ç å‹ç¼©ç­–ç•¥:
        1. ASTè§£ææå–å‡½æ•°ç­¾å
        2. ä¿ç•™æ ¸å¿ƒé€»è¾‘å—
        3. ç§»é™¤æ³¨é‡Š/ç©ºè¡Œ
        4. CodeBERTè¯­ä¹‰å‹ç¼©
        """
        import ast
        tree = ast.parse(code)

        # æå–å‡½æ•°å®šä¹‰
        functions = [node for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)]

        # æå–æ ¸å¿ƒä»£ç å—(ç®€åŒ–)
        core_code = "\n".join([ast.get_source_segment(code, func) for func in functions])

        return core_code[:int(len(core_code) * ratio)]
```

**`text_compressor.py`** (åŸºäºsummaåº“):
```python
from summa.summarizer import summarize

def compress_text(text: str, ratio: float) -> str:
    """TextRankæ‘˜è¦"""
    try:
        return summarize(text, ratio=ratio)
    except:
        # é™çº§ç­–ç•¥:ç®€å•æˆªæ–­
        return text[:int(len(text) * ratio)]
```

---

## ğŸ¯ Phase 5: å¹»è§‰æŠ‘åˆ¶æœåŠ¡å®ç°

### æ–‡ä»¶: `src/mcp_core/services/hallucination_service.py`

```python
class HallucinationValidationService:
    def detect_hallucination(self, project_id, output, threshold):
        """
        æ£€æµ‹æµç¨‹:
        1. ç”ŸæˆoutputåµŒå…¥
        2. æ£€ç´¢ç›¸å…³è®°å¿†(Top-3)
        3. è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        4. è‡ªé€‚åº”è°ƒæ•´é˜ˆå€¼:
           - é•¿æŸ¥è¯¢: -5%
           - ä»£ç å—: -8%
           - æŠ€æœ¯æœ¯è¯­å¯†é›†: -5%
        5. åˆ¤æ–­is_hallucination
        """
        output_embedding = self.embedding_service.encode_single(output)

        # æ£€ç´¢ç›¸å…³è®°å¿†
        memories = self.memory_service.retrieve_memory(
            project_id, output, top_k=3, memory_levels=["mid", "long"]
        )

        if not memories["memories"]:
            return {"is_hallucination": True, "confidence": 0.0, "reason": "æ— ç›¸å…³è®°å¿†"}

        # è®¡ç®—ç›¸ä¼¼åº¦
        similarities = []
        for mem in memories["memories"]:
            mem_embedding = self.embedding_service.encode_single(mem["content"])
            sim = cosine_similarity(output_embedding, mem_embedding)
            similarities.append(sim)

        avg_similarity = np.mean(similarities)

        # è‡ªé€‚åº”é˜ˆå€¼
        adjusted_threshold = self._calculate_adaptive_threshold(output, threshold)

        return {
            "is_hallucination": avg_similarity < adjusted_threshold,
            "confidence": avg_similarity,
            "matched_memories": [m["memory_id"] for m in memories["memories"]],
            "threshold_used": adjusted_threshold
        }

    def _calculate_adaptive_threshold(self, output, base_threshold):
        """
        è‡ªé€‚åº”é˜ˆå€¼ç®—æ³•(5ä¸ªç»´åº¦):
        1. æŸ¥è¯¢é•¿åº¦: >200å­—ç¬¦ -> -0.05
        2. ä»£ç å—æ•°é‡: >2ä¸ª -> -0.08
        3. æŠ€æœ¯æœ¯è¯­: â‰¥3ä¸ª -> -0.05
        4. è®°å¿†æ•°é‡: <10æ¡ -> +0.05
        5. ç”¨æˆ·å†å²å¹»è§‰ç‡: >10% -> +0.10
        """
        adjustments = []

        if len(output) > 200:
            adjustments.append(-0.05)

        if output.count("```") > 2:
            adjustments.append(-0.08)

        tech_terms = ["API", "æ•°æ®åº“", "æ¡†æ¶", "æ¥å£"]
        if sum(1 for term in tech_terms if term in output) >= 3:
            adjustments.append(-0.05)

        final = base_threshold + sum(adjustments)
        return max(0.4, min(0.85, final))  # é™åˆ¶[0.4, 0.85]
```

---

## ğŸ¯ Phase 6: APIå±‚ä¸æƒé™ç³»ç»Ÿå®ç°

### 6.1 FastAPIä¸»åº”ç”¨

**æ–‡ä»¶**: `src/mcp_core/main.py`

```python
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from prometheus_client import make_asgi_app

app = FastAPI(
    title="MCP Core API",
    version="1.0.0",
    description="è®°å¿†æ§åˆ¶æœºåˆ¶REST API"
)

# CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.security.cors_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ³¨å†Œè·¯ç”±
from .api.v1 import memory, token, hallucination, auth, project

app.include_router(auth.router, prefix="/api/v1/auth", tags=["è®¤è¯"])
app.include_router(memory.router, prefix="/api/v1/memory", tags=["è®°å¿†ç®¡ç†"])
app.include_router(token.router, prefix="/api/v1/token", tags=["Tokenä¼˜åŒ–"])
app.include_router(hallucination.router, prefix="/api/v1/validate", tags=["å¹»è§‰æ£€æµ‹"])
app.include_router(project.router, prefix="/api/v1/project", tags=["é¡¹ç›®ç®¡ç†"])

# PrometheusæŒ‡æ ‡
metrics_app = make_asgi_app()
app.mount("/metrics", metrics_app)

# å¥åº·æ£€æŸ¥
@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "timestamp": utc_now().isoformat(),
        "version": "1.0.0"
    }
```

### 6.2 æƒé™ç³»ç»Ÿ

**æ–‡ä»¶**: `src/mcp_core/api/dependencies/auth.py`

```python
from fastapi import Depends, HTTPException
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from jose import JWTError, jwt

security = HTTPBearer()

async def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """ä»JWTæå–ç”¨æˆ·"""
    try:
        payload = jwt.decode(credentials.credentials, settings.security.jwt.secret_key, algorithms=["HS256"])
        user_id = payload.get("sub")
        if not user_id:
            raise HTTPException(status_code=401, detail="æ— æ•ˆToken")
        return user_id
    except JWTError:
        raise HTTPException(status_code=401, detail="TokenéªŒè¯å¤±è´¥")

def require_permission(permission: str):
    """æƒé™æ£€æŸ¥è£…é¥°å™¨"""
    async def check_perm(
        project_id: str,
        current_user: str = Depends(get_current_user),
        db: Session = Depends(get_db)
    ):
        # æŸ¥è¯¢æƒé™
        perm = db.query(UserPermission).filter(
            UserPermission.user_id == current_user,
            UserPermission.project_id == project_id,
            UserPermission.permission == permission
        ).first()

        if not perm:
            raise HTTPException(status_code=403, detail=f"ç¼ºå°‘æƒé™: {permission}")

        # æ£€æŸ¥è¿‡æœŸ
        if perm.expires_at and perm.expires_at < utc_now():
            raise HTTPException(status_code=403, detail="æƒé™å·²è¿‡æœŸ")

        return current_user

    return check_perm
```

### 6.3 APIè·¯ç”±ç¤ºä¾‹

**æ–‡ä»¶**: `src/mcp_core/api/v1/memory.py`

```python
from fastapi import APIRouter, Depends
from sqlalchemy.orm import Session

router = APIRouter()

@router.post("/store", response_model=BaseResponse)
async def store_memory(
    request: MemoryStoreRequest,
    current_user: str = Depends(require_permission("memory:write")),
    db: Session = Depends(get_db)
):
    """å­˜å‚¨è®°å¿†"""
    memory_service = MemoryService(db)
    result = memory_service.store_memory(
        project_id=request.project_id,
        content=request.content,
        memory_level=request.memory_level,
        metadata=request.metadata
    )

    # è®°å½•å®¡è®¡æ—¥å¿—
    audit_log = AuditLog(
        user_id=current_user,
        project_id=request.project_id,
        action="memory_store",
        resource_type="memory",
        resource_id=result["memory_id"]
    )
    db.add(audit_log)
    db.commit()

    return BaseResponse(data=result)

@router.get("/retrieve", response_model=BaseResponse)
async def retrieve_memory(
    project_id: str,
    query: str,
    top_k: int = 5,
    current_user: str = Depends(require_permission("memory:read")),
    db: Session = Depends(get_db)
):
    """æ£€ç´¢è®°å¿†"""
    memory_service = MemoryService(db)
    result = memory_service.retrieve_memory(project_id, query, top_k)

    return BaseResponse(data=result)
```

---

## ğŸ¯ Phase 7: ç›‘æ§ä¸æ—¥å¿—ç³»ç»Ÿå®ç°

### 7.1 PrometheusæŒ‡æ ‡

**æ–‡ä»¶**: `src/mcp_core/services/metrics.py`

```python
from prometheus_client import Counter, Histogram, Gauge

# ä¸šåŠ¡æŒ‡æ ‡
memory_operations = Counter(
    'mcp_memory_operations_total',
    'Total memory operations',
    ['operation', 'memory_level', 'project_id']
)

memory_retrieval_latency = Histogram(
    'mcp_memory_retrieval_latency_seconds',
    'Memory retrieval latency',
    ['project_id'],
    buckets=[0.05, 0.1, 0.2, 0.3, 0.5, 1.0]
)

token_saved = Counter(
    'mcp_token_saved_total',
    'Total tokens saved',
    ['project_id', 'content_type']
)

# ä½¿ç”¨ç¤ºä¾‹
def track_memory_store(project_id, memory_level):
    memory_operations.labels(
        operation="store",
        memory_level=memory_level,
        project_id=project_id
    ).inc()
```

---

## ğŸ¯ Phase 8-9: æµ‹è¯•ä¸éƒ¨ç½²

### 8.1 å•å…ƒæµ‹è¯•ç¤ºä¾‹

**æ–‡ä»¶**: `tests/unit/test_memory_service.py`

```python
import pytest
from src.mcp_core.services.memory_service import MemoryService

@pytest.fixture
def memory_service(db_session):
    return MemoryService(db_session)

def test_store_short_memory(memory_service):
    result = memory_service.store_memory(
        project_id="test_proj",
        content="æµ‹è¯•å†…å®¹",
        memory_level="short"
    )
    assert "memory_id" in result
    assert result["memory_id"].startswith("mem_")

def test_retrieve_memory_performance(memory_service):
    import time
    start = time.time()
    result = memory_service.retrieve_memory("test_proj", "æµ‹è¯•æŸ¥è¯¢", 5)
    elapsed = time.time() - start
    assert elapsed < 0.3  # å¿…é¡»<300ms
```

### 8.2 Docker Compose

**æ–‡ä»¶**: `docker-compose.yml`

```yaml
version: '3.8'
services:
  mcp-api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://...
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
      - milvus

  postgres:
    image: postgres:15-alpine
    ...

  redis:
    image: redis:7-alpine
    ...

  milvus:
    image: milvusdb/milvus:v2.3.4
    ...
```

---

## âœ… å®Œæˆæ ‡å‡†

æ¯ä¸ªPhaseçš„éªŒæ”¶æ¸…å•:

**Phase 3**:
- [ ] Redisè¿æ¥æ­£å¸¸
- [ ] Milvus Collectionåˆ›å»ºæˆåŠŸ
- [ ] è®°å¿†å­˜å‚¨/æ£€ç´¢æµ‹è¯•é€šè¿‡
- [ ] æ€§èƒ½æµ‹è¯•:æ£€ç´¢<300ms

**Phase 4**:
- [ ] Tokenå‹ç¼©ç‡â‰¥80%
- [ ] è¯­ä¹‰ä¿ç•™åº¦æµ‹è¯•é€šè¿‡

**Phase 5**:
- [ ] å¹»è§‰æ£€æµ‹å‡†ç¡®ç‡â‰¥95%
- [ ] è¾¹ç¼˜æ¡ˆä¾‹æµ‹è¯•é€šè¿‡

**Phase 6**:
- [ ] æ‰€æœ‰APIç«¯ç‚¹æµ‹è¯•é€šè¿‡
- [ ] æƒé™ç³»ç»ŸéªŒè¯é€šè¿‡
- [ ] OpenAPIæ–‡æ¡£ç”Ÿæˆ

**Phase 7**:
- [ ] PrometheusæŒ‡æ ‡é‡‡é›†æ­£å¸¸
- [ ] Grafanaä»ªè¡¨ç›˜é…ç½®å®Œæˆ

**Phase 8**:
- [ ] æµ‹è¯•è¦†ç›–ç‡â‰¥70%
- [ ] æ€§èƒ½å‹æµ‹100 QPSé€šè¿‡

**Phase 9**:
- [ ] Dockeré•œåƒæ„å»ºæˆåŠŸ
- [ ] æ–‡æ¡£å®Œæ•´
- [ ] éƒ¨ç½²æ–‡æ¡£éªŒè¯

---

**é¢„è®¡æ€»å·¥æ—¶**: 24å°æ—¶
**å½“å‰è¿›åº¦**: 6å°æ—¶ (25%)
**ä¸‹ä¸€é‡Œç¨‹ç¢‘**: Phase 3å®Œæˆ(é¢„è®¡+4å°æ—¶)
