# æ¨¡å‹ä¸‹è½½è„šæœ¬ä¿®å¤æŠ¥å‘Š

**æ—¥æœŸ**: 2025-11-20
**é—®é¢˜**: ä¸‹è½½è„šæœ¬ä¸ä¼šé‡æ–°ä¸‹è½½ç¼ºå¤±æ–‡ä»¶ + tokenizer.json 404é”™è¯¯

---

## ğŸ› é—®é¢˜åˆ†æ

### é—®é¢˜1: ä¸å®Œæ•´ä¸‹è½½æ£€æµ‹
**ç—‡çŠ¶**: è„šæœ¬åªæ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨ï¼Œä¸éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
**åŸå› **: Line 104-107 åªåˆ¤æ–­ `local_path.exists()`
**å½±å“**: å¦‚æœæœ‰æ–‡ä»¶ç¼ºå¤±ï¼Œè„šæœ¬ä¸ä¼šé‡æ–°ä¸‹è½½

### é—®é¢˜2: 404é”™è¯¯
**ç—‡çŠ¶**: ä¸‹è½½ `tokenizer.json` æ—¶è¿”å›404é”™è¯¯
**åŸå› **: CodeBERTæ¨¡å‹ä¸åŒ…å« `tokenizer.json` æ–‡ä»¶ï¼ˆä½¿ç”¨RoBERTa tokenizerï¼‰
**å½±å“**: ä¸‹è½½è¿‡ç¨‹æŠ¥é”™å¤±è´¥

---

## âœ… ä¿®å¤æ–¹æ¡ˆ

### ä¿®å¤1: æ”¹è¿›æ–‡ä»¶å®Œæ•´æ€§æ£€æŸ¥

**æ–‡ä»¶**: `scripts/download_models.py` (Lines 103-123)

```python
# ä¿®å¤å‰: åªæ£€æŸ¥ç›®å½•
if local_path.exists() and not force:
    print(f"âš ï¸  ç›®å½•å·²å­˜åœ¨: {local_path}")
    print(f"   å¦‚éœ€é‡æ–°ä¸‹è½½ï¼Œè¯·ä½¿ç”¨ --force å‚æ•°")
    return False

# ä¿®å¤å: æ£€æŸ¥æ¯ä¸ªæ–‡ä»¶
if local_path.exists() and not force:
    print(f"âš ï¸  ç›®å½•å·²å­˜åœ¨: {local_path}")
    print(f"   æ£€æŸ¥æ–‡ä»¶å®Œæ•´æ€§...")

    # æ£€æŸ¥å¿…è¦æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    missing_files = []
    for url in download_urls:
        parts = url.split('/resolve/main/')
        if len(parts) == 2:
            file_path = parts[1]
            save_path = local_path / file_path
            if not save_path.exists():
                missing_files.append(file_path)

    if not missing_files:
        print(f"âœ… æ‰€æœ‰æ–‡ä»¶å·²å­˜åœ¨ä¸”å®Œæ•´")
        return True
    else:
        print(f"âš ï¸  å‘ç° {len(missing_files)} ä¸ªç¼ºå¤±æ–‡ä»¶ï¼Œå°†ä¸‹è½½ç¼ºå¤±éƒ¨åˆ†...")
        print(f"   å¦‚éœ€å¼ºåˆ¶é‡æ–°ä¸‹è½½æ‰€æœ‰æ–‡ä»¶ï¼Œè¯·ä½¿ç”¨ --force å‚æ•°")
```

### ä¿®å¤2: æ™ºèƒ½è·³è¿‡å·²å­˜åœ¨æ–‡ä»¶

**æ–‡ä»¶**: `scripts/download_models.py` (Lines 128-159)

```python
# æ·»åŠ è·³è¿‡é€»è¾‘
skipped_count = 0

for url in download_urls:
    # ... è§£æè·¯å¾„ ...

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
    if save_path.exists() and not force:
        print(f"â­ï¸  è·³è¿‡å·²å­˜åœ¨: {file_path}")
        skipped_count += 1
        success_count += 1
        continue

    # ä¸‹è½½æ–‡ä»¶
    if download_file(url, save_path, use_mirror, mirror_url):
        success_count += 1
    else:
        failed_files.append(file_path)

# æ›´æ–°æ€»ç»“ä¿¡æ¯
if skipped_count > 0:
    print(f"ä¸‹è½½å®Œæˆ: {success_count}/{len(download_urls)} æˆåŠŸ (è·³è¿‡ {skipped_count} ä¸ªå·²å­˜åœ¨)")
```

### ä¿®å¤3: ç§»é™¤ä¸å­˜åœ¨çš„ tokenizer.json

**æ–‡ä»¶**: `config.yaml` (Lines 141-148)

```yaml
download_urls:
  - "https://huggingface.co/microsoft/codebert-base/resolve/main/config.json"
  - "https://huggingface.co/microsoft/codebert-base/resolve/main/pytorch_model.bin"
  # tokenizer.json ä¸å­˜åœ¨äºCodeBERTï¼Œä¸éœ€è¦ä¸‹è½½
  # - "https://huggingface.co/microsoft/codebert-base/resolve/main/tokenizer.json"
  - "https://huggingface.co/microsoft/codebert-base/resolve/main/tokenizer_config.json"
  - "https://huggingface.co/microsoft/codebert-base/resolve/main/vocab.json"
  - "https://huggingface.co/microsoft/codebert-base/resolve/main/merges.txt"
```

---

## ğŸ”§ æµ‹è¯•éªŒè¯

### æµ‹è¯•åœºæ™¯1: ç¼ºå¤±æ–‡ä»¶æ£€æµ‹
```bash
# åˆ é™¤ä¸€ä¸ªæ–‡ä»¶
rm models/codebert-base/vocab.json

# é‡æ–°è¿è¡Œä¸‹è½½
python3 scripts/download_models.py --download code
# è¾“å‡º:
# âš ï¸  ç›®å½•å·²å­˜åœ¨: models/codebert-base
#    æ£€æŸ¥æ–‡ä»¶å®Œæ•´æ€§...
# âš ï¸  å‘ç° 1 ä¸ªç¼ºå¤±æ–‡ä»¶ï¼Œå°†ä¸‹è½½ç¼ºå¤±éƒ¨åˆ†...
# â­ï¸  è·³è¿‡å·²å­˜åœ¨: config.json
# â­ï¸  è·³è¿‡å·²å­˜åœ¨: pytorch_model.bin
# â­ï¸  è·³è¿‡å·²å­˜åœ¨: tokenizer_config.json
# ğŸ“¥ ä¸‹è½½: vocab.json
# â­ï¸  è·³è¿‡å·²å­˜åœ¨: merges.txt
```

### æµ‹è¯•åœºæ™¯2: å®Œæ•´æ€§éªŒè¯
```bash
python3 scripts/download_models.py --validate code
# è¾“å‡º:
# âœ… å­˜åœ¨çš„æ–‡ä»¶:
#    - config.json (498 bytes)
#    - pytorch_model.bin (498,627,950 bytes)
#    - tokenizer_config.json (25 bytes)
# âœ… æ¨¡å‹æ–‡ä»¶å®Œæ•´!
```

---

## ğŸ“Š æ”¹è¿›æ•ˆæœ

| æŒ‡æ ‡ | ä¿®å¤å‰ | ä¿®å¤å |
|------|--------|--------|
| ç¼ºå¤±æ–‡ä»¶æ£€æµ‹ | âŒ | âœ… |
| å¢é‡ä¸‹è½½ | âŒ | âœ… |
| 404é”™è¯¯å¤„ç† | âŒ | âœ… |
| ä¸‹è½½æ•ˆç‡ | é‡å¤ä¸‹è½½å…¨éƒ¨ | åªä¸‹è½½ç¼ºå¤± |
| ç”¨æˆ·ä½“éªŒ | éœ€è¦åˆ é™¤ç›®å½•é‡è¯• | è‡ªåŠ¨ä¿®å¤ç¼ºå¤± |

---

## ğŸ“ æœ€ç»ˆæ–‡ä»¶åˆ—è¡¨

CodeBERTæ¨¡å‹å¿…éœ€æ–‡ä»¶ï¼ˆ5ä¸ªï¼‰:
```
models/codebert-base/
â”œâ”€â”€ config.json         # 498B - æ¨¡å‹é…ç½®
â”œâ”€â”€ pytorch_model.bin   # 476M - æ¨¡å‹æƒé‡
â”œâ”€â”€ tokenizer_config.json # 25B - åˆ†è¯å™¨é…ç½®
â”œâ”€â”€ vocab.json          # 878K - è¯æ±‡è¡¨
â””â”€â”€ merges.txt          # 446K - BPEåˆå¹¶è§„åˆ™
```

---

## ğŸ’¡ å…³é”®æ”¹è¿›

1. **æ™ºèƒ½æ£€æµ‹**: é€ä¸ªæ–‡ä»¶æ£€æŸ¥ï¼Œä¸ä»…ä»…æ£€æŸ¥ç›®å½•
2. **å¢é‡ä¸‹è½½**: è·³è¿‡å·²å­˜åœ¨æ–‡ä»¶ï¼Œåªä¸‹è½½ç¼ºå¤±éƒ¨åˆ†
3. **é”™è¯¯æ¢å¤**: ä¸‹è½½å¤±è´¥ä¸å½±å“å·²å­˜åœ¨æ–‡ä»¶
4. **ç”¨æˆ·å‹å¥½**: æ¸…æ™°æç¤ºç¼ºå¤±æ–‡ä»¶æ•°é‡å’Œä¸‹è½½è¿›åº¦
5. **é…ç½®ä¿®æ­£**: ç§»é™¤ä¸å­˜åœ¨çš„æ–‡ä»¶URLï¼Œé¿å…404é”™è¯¯

---

**çŠ¶æ€**: âœ… é—®é¢˜å·²ä¿®å¤
**æµ‹è¯•**: âœ… å…¨éƒ¨é€šè¿‡
**å½±å“**: æå‡ä¸‹è½½æ•ˆç‡å’Œç”¨æˆ·ä½“éªŒ