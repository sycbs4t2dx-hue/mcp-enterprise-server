#!/usr/bin/env python3
"""
æŠ€æœ¯å€ºåŠ¡æ¸…ç†è„šæœ¬
è‡ªåŠ¨åŒ–æ¸…ç†MCPé¡¹ç›®ä¸­çš„æŠ€æœ¯å€ºåŠ¡
"""

import os
import re
import sys
from pathlib import Path
from typing import List, Tuple, Dict

class TechnicalDebtCleaner:
    """æŠ€æœ¯å€ºåŠ¡æ¸…ç†å™¨"""

    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.issues_found = []
        self.fixes_applied = []

    def scan_and_fix_bare_excepts(self, file_path: Path) -> int:
        """ä¿®å¤bare exceptè¯­å¥"""
        fixes = 0
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # æŸ¥æ‰¾bare except
            bare_except_pattern = r'(\s+)except\s*:\s*$'

            # æ›¿æ¢ä¸ºexcept Exception
            new_content = re.sub(
                bare_except_pattern,
                r'\1except Exception:',
                content,
                flags=re.MULTILINE
            )

            if new_content != content:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(new_content)
                fixes = content.count('except:') - new_content.count('except:')
                self.fixes_applied.append(f"Fixed {fixes} bare except(s) in {file_path}")

        except Exception as e:
            print(f"Error processing {file_path}: {e}")

        return fixes

    def replace_print_with_logger(self, file_path: Path) -> int:
        """å°†printè¯­å¥æ›¿æ¢ä¸ºloggerè°ƒç”¨"""
        fixes = 0
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()

            modified = False
            has_logger = False

            # æ£€æŸ¥æ˜¯å¦å·²æœ‰logger
            for line in lines:
                if 'logger = get_logger' in line or 'logger = logging.getLogger' in line:
                    has_logger = True
                    break

            # å¦‚æœæ²¡æœ‰loggerï¼Œéœ€è¦æ·»åŠ 
            if not has_logger:
                # æŸ¥æ‰¾importè¯­å¥çš„ä½ç½®
                import_index = 0
                for i, line in enumerate(lines):
                    if line.strip().startswith('import ') or line.strip().startswith('from '):
                        import_index = i + 1

                # æ·»åŠ loggerå¯¼å…¥
                lines.insert(import_index, 'import logging\n')
                lines.insert(import_index + 1, '\n')
                lines.insert(import_index + 2, 'logger = logging.getLogger(__name__)\n')
                lines.insert(import_index + 3, '\n')
                modified = True

            # æ›¿æ¢printè¯­å¥
            for i, line in enumerate(lines):
                if 'print(' in line and not line.strip().startswith('#'):
                    # æå–printå†…å®¹
                    match = re.search(r'print\((.*)\)', line)
                    if match:
                        content = match.group(1)
                        indent = len(line) - len(line.lstrip())

                        # åˆ¤æ–­æ—¥å¿—çº§åˆ«
                        if 'error' in content.lower() or 'exception' in content.lower():
                            new_line = ' ' * indent + f'logger.error({content})\n'
                        elif 'warn' in content.lower():
                            new_line = ' ' * indent + f'logger.warning({content})\n'
                        elif 'debug' in content.lower():
                            new_line = ' ' * indent + f'logger.debug({content})\n'
                        else:
                            new_line = ' ' * indent + f'logger.info({content})\n'

                        lines[i] = new_line
                        modified = True
                        fixes += 1

            if modified:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.writelines(lines)
                self.fixes_applied.append(f"Replaced {fixes} print statement(s) in {file_path}")

        except Exception as e:
            print(f"Error processing {file_path}: {e}")

        return fixes

    def remove_unused_imports(self, file_path: Path) -> int:
        """ç§»é™¤æœªä½¿ç”¨çš„å¯¼å…¥"""
        fixes = 0
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # ç‰¹å®šçš„æœªä½¿ç”¨å¯¼å…¥ï¼ˆåŸºäºæ‰«æç»“æœï¼‰
            unused_imports = {
                'mcp_server_enterprise.py': ['hashlib'],
            }

            file_name = file_path.name
            if file_name in unused_imports:
                for unused in unused_imports[file_name]:
                    # ç§»é™¤å¯¼å…¥è¡Œ
                    pattern = f'^import {unused}$|^from .* import .*{unused}.*$'
                    new_content = re.sub(
                        pattern,
                        '',
                        content,
                        flags=re.MULTILINE
                    )

                    if new_content != content:
                        # æ¸…ç†å¤šä½™çš„ç©ºè¡Œ
                        new_content = re.sub(r'\n\n\n+', '\n\n', new_content)

                        with open(file_path, 'w', encoding='utf-8') as f:
                            f.write(new_content)
                        fixes += 1
                        self.fixes_applied.append(f"Removed unused import '{unused}' from {file_path}")
                        content = new_content

        except Exception as e:
            print(f"Error processing {file_path}: {e}")

        return fixes

    def standardize_logging_format(self, file_path: Path) -> int:
        """æ ‡å‡†åŒ–æ—¥å¿—æ ¼å¼"""
        fixes = 0
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # æ ‡å‡†åŒ–æ—¥å¿—æ ¼å¼
            patterns = [
                # logger.info("message") -> logger.info("message")
                (r'logger\.(info|debug|warning|error)\("([^"]+)"\s*%\s*([^)]+)\)',
                 r'logger.\1(f"\2{\3}")'),
                # logger.info("message %s" % var) -> logger.info(f"message {var}")
                (r'logger\.(info|debug|warning|error)\("([^"]+)%s([^"]*)"[,\s]*%\s*([^)]+)\)',
                 r'logger.\1(f"\2{\4}\3")'),
            ]

            for pattern, replacement in patterns:
                new_content = re.sub(pattern, replacement, content)
                if new_content != content:
                    fixes += 1
                    content = new_content

            if fixes > 0:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                self.fixes_applied.append(f"Standardized {fixes} log format(s) in {file_path}")

        except Exception as e:
            print(f"Error processing {file_path}: {e}")

        return fixes

    def clean_commented_code(self, file_path: Path) -> int:
        """æ¸…ç†æ³¨é‡Šæ‰çš„ä»£ç ï¼ˆä¿ç•™æ–‡æ¡£æ³¨é‡Šï¼‰"""
        fixes = 0
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()

            modified = False
            new_lines = []

            for i, line in enumerate(lines):
                # è·³è¿‡æ–‡æ¡£å­—ç¬¦ä¸²å’Œæœ‰ç”¨çš„æ³¨é‡Š
                if line.strip().startswith('#') and not any(
                    keyword in line.lower() for keyword in ['todo', 'fixme', 'note', 'warning', 'deprecated', 'âŒ']
                ):
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ³¨é‡Šæ‰çš„ä»£ç 
                    commented_code_patterns = [
                        r'^\s*#\s*(import|from|def|class|if|for|while|try|except|return)\s',
                        r'^\s*#\s*[a-zA-Z_][a-zA-Z0-9_]*\s*=',  # å˜é‡èµ‹å€¼
                        r'^\s*#\s*[a-zA-Z_][a-zA-Z0-9_]*\(',     # å‡½æ•°è°ƒç”¨
                    ]

                    is_code = any(re.match(pattern, line) for pattern in commented_code_patterns)

                    if is_code:
                        modified = True
                        fixes += 1
                        continue  # è·³è¿‡è¿™ä¸€è¡Œ

                new_lines.append(line)

            if modified:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.writelines(new_lines)
                self.fixes_applied.append(f"Removed {fixes} commented code line(s) from {file_path}")

        except Exception as e:
            print(f"Error processing {file_path}: {e}")

        return fixes

    def process_file(self, file_path: Path) -> Dict[str, int]:
        """å¤„ç†å•ä¸ªæ–‡ä»¶çš„æ‰€æœ‰æŠ€æœ¯å€ºåŠ¡"""
        results = {
            'bare_excepts': 0,
            'print_statements': 0,
            'unused_imports': 0,
            'log_formats': 0,
            'commented_code': 0
        }

        if file_path.suffix == '.py':
            print(f"Processing {file_path}...")

            results['bare_excepts'] = self.scan_and_fix_bare_excepts(file_path)
            results['print_statements'] = self.replace_print_with_logger(file_path)
            results['unused_imports'] = self.remove_unused_imports(file_path)
            results['log_formats'] = self.standardize_logging_format(file_path)
            results['commented_code'] = self.clean_commented_code(file_path)

        return results

    def run(self, target_files: List[str] = None):
        """è¿è¡ŒæŠ€æœ¯å€ºåŠ¡æ¸…ç†"""
        total_results = {
            'bare_excepts': 0,
            'print_statements': 0,
            'unused_imports': 0,
            'log_formats': 0,
            'commented_code': 0
        }

        if target_files:
            # å¤„ç†æŒ‡å®šæ–‡ä»¶
            for file_path in target_files:
                path = Path(file_path)
                if path.exists():
                    results = self.process_file(path)
                    for key in total_results:
                        total_results[key] += results[key]
        else:
            # å¤„ç†æ‰€æœ‰Pythonæ–‡ä»¶
            for file_path in self.project_root.rglob('*.py'):
                # è·³è¿‡è™šæ‹Ÿç¯å¢ƒå’Œæµ‹è¯•æ–‡ä»¶
                if 'venv' in str(file_path) or '__pycache__' in str(file_path):
                    continue

                results = self.process_file(file_path)
                for key in total_results:
                    total_results[key] += results[key]

        # ç”ŸæˆæŠ¥å‘Š
        self.generate_report(total_results)

    def generate_report(self, results: Dict[str, int]):
        """ç”Ÿæˆæ¸…ç†æŠ¥å‘Š"""
        print("\n" + "=" * 60)
        print("æŠ€æœ¯å€ºåŠ¡æ¸…ç†æŠ¥å‘Š")
        print("=" * 60)

        print("\nğŸ“Š æ¸…ç†ç»Ÿè®¡:")
        print(f"  â€¢ Bare exceptè¯­å¥ä¿®å¤: {results['bare_excepts']}")
        print(f"  â€¢ Printè¯­å¥æ›¿æ¢ä¸ºlogger: {results['print_statements']}")
        print(f"  â€¢ æœªä½¿ç”¨å¯¼å…¥ç§»é™¤: {results['unused_imports']}")
        print(f"  â€¢ æ—¥å¿—æ ¼å¼æ ‡å‡†åŒ–: {results['log_formats']}")
        print(f"  â€¢ æ³¨é‡Šä»£ç æ¸…ç†: {results['commented_code']}")

        total_fixes = sum(results.values())
        print(f"\nâœ… æ€»è®¡ä¿®å¤: {total_fixes} ä¸ªé—®é¢˜")

        if self.fixes_applied:
            print("\nğŸ“ è¯¦ç»†ä¿®å¤åˆ—è¡¨:")
            for fix in self.fixes_applied:
                print(f"  â€¢ {fix}")

        print("\n" + "=" * 60)


def main():
    """ä¸»å‡½æ•°"""
    # é«˜ä¼˜å…ˆçº§æ¸…ç†æ–‡ä»¶
    priority_files = [
        '/Users/mac/Downloads/MCP/mcp_server_enterprise.py',
        '/Users/mac/Downloads/MCP/src/mcp_core/code_analyzer.py',
        '/Users/mac/Downloads/MCP/src/mcp_core/multi_lang_analyzer.py',
        '/Users/mac/Downloads/MCP/src/mcp_core/services/error_firewall.py',
        '/Users/mac/Downloads/MCP/src/mcp_core/services/experience_manager.py',
        '/Users/mac/Downloads/MCP/src/mcp_core/swift_analyzer.py',
        '/Users/mac/Downloads/MCP/src/mcp_core/quality_guardian_service.py',
    ]

    cleaner = TechnicalDebtCleaner('/Users/mac/Downloads/MCP')

    print("ğŸ§¹ å¼€å§‹æŠ€æœ¯å€ºåŠ¡æ¸…ç†...")
    print(f"ç›®æ ‡æ–‡ä»¶: {len(priority_files)} ä¸ªé«˜ä¼˜å…ˆçº§æ–‡ä»¶")

    # è¿è¡Œæ¸…ç†
    cleaner.run(priority_files)

    print("\nâœ¨ æŠ€æœ¯å€ºåŠ¡æ¸…ç†å®Œæˆ!")


if __name__ == "__main__":
    main()