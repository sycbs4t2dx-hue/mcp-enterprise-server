"""
MCPè®°å¿†å·¥å…· - è‡ªåŠ¨ä¿å­˜å’Œæ¢å¤é¡¹ç›®è®°å¿†
æ•´åˆå›¾è°±ç”Ÿæˆä¸è®°å¿†ç³»ç»Ÿï¼Œå®ç°é¡¹ç›®çš„æ™ºèƒ½è®°å¿†ç®¡ç†
"""

import os
import asyncio
from typing import Dict, Any, Optional, List
from datetime import datetime, timedelta
from pathlib import Path

from src.mcp_core.services.project_memory_system import (
    ProjectMemorySystem,
    MemoryQuery,
    MemoryRecoveryAssistant
)
from src.mcp_core.common.logger import get_logger

logger = get_logger(__name__)

# ============================================
# MCPè®°å¿†å·¥å…·
# ============================================

class MemoryTool:
    """MCPè®°å¿†å·¥å…·åŸºç±»"""
    name: str = ""
    description: str = ""
    parameters: Dict[str, Any] = {}

    async def execute(self, **kwargs) -> Dict[str, Any]:
        raise NotImplementedError

class SaveMemoryTool(MemoryTool):
    """ä¿å­˜é¡¹ç›®è®°å¿†å·¥å…·"""

    name = "save_project_memory"
    description = "åˆ›å»ºé¡¹ç›®çš„è®°å¿†å¿«ç…§ï¼Œä¿å­˜å½“å‰çŠ¶æ€"

    parameters = {
        "type": "object",
        "properties": {
            "project_path": {
                "type": "string",
                "description": "é¡¹ç›®è·¯å¾„ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•"
            },
            "trigger": {
                "type": "string",
                "enum": ["manual", "auto", "commit", "error", "milestone"],
                "description": "è§¦å‘ç±»å‹"
            },
            "message": {
                "type": "string",
                "description": "å¿«ç…§è¯´æ˜ä¿¡æ¯"
            }
        },
        "required": []
    }

    def __init__(self):
        self.memory_system = ProjectMemorySystem()

    async def execute(self, **kwargs) -> Dict[str, Any]:
        """æ‰§è¡Œè®°å¿†ä¿å­˜"""
        try:
            project_path = kwargs.get('project_path', os.getcwd())
            trigger = kwargs.get('trigger', 'manual')
            message = kwargs.get('message', '')

            # åˆ›å»ºå¿«ç…§
            snapshot = await self.memory_system.create_snapshot(
                project_path=project_path,
                trigger=trigger,
                context={"message": message} if message else None
            )

            return {
                "success": True,
                "snapshot_id": snapshot.id,
                "timestamp": snapshot.timestamp.isoformat(),
                "stats": {
                    "nodes": len(snapshot.graph_data.nodes),
                    "edges": len(snapshot.graph_data.edges),
                    "hash": snapshot.hash
                },
                "insights": snapshot.insights,
                "message": f"è®°å¿†å¿«ç…§å·²ä¿å­˜: {snapshot.id}"
            }

        except Exception as e:
            logger.error(f"ä¿å­˜è®°å¿†å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e)
            }

class RecoverMemoryTool(MemoryTool):
    """æ¢å¤é¡¹ç›®è®°å¿†å·¥å…·"""

    name = "recover_project_memory"
    description = "ä»å†å²å¿«ç…§ä¸­æ¢å¤é¡¹ç›®è®°å¿†"

    parameters = {
        "type": "object",
        "properties": {
            "project_path": {
                "type": "string",
                "description": "é¡¹ç›®è·¯å¾„"
            },
            "query_type": {
                "type": "string",
                "enum": ["similarity", "time_range", "file_history", "pattern"],
                "description": "æŸ¥è¯¢ç±»å‹"
            },
            "file_path": {
                "type": "string",
                "description": "æ–‡ä»¶è·¯å¾„ (ç”¨äºfile_historyæŸ¥è¯¢)"
            },
            "days_ago": {
                "type": "integer",
                "description": "å¤šå°‘å¤©å‰çš„è®°å¿†"
            }
        },
        "required": ["query_type"]
    }

    def __init__(self):
        self.memory_system = ProjectMemorySystem()

    async def execute(self, **kwargs) -> Dict[str, Any]:
        """æ‰§è¡Œè®°å¿†æ¢å¤"""
        try:
            project_path = kwargs.get('project_path', os.getcwd())
            query_type = kwargs['query_type']

            # æ„å»ºæŸ¥è¯¢
            query_params = {}

            if query_type == "file_history":
                file_path = kwargs.get('file_path')
                if not file_path:
                    return {
                        "success": False,
                        "error": "file_historyæŸ¥è¯¢éœ€è¦æä¾›file_path"
                    }
                query_params['file_path'] = file_path

            elif query_type == "time_range":
                days_ago = kwargs.get('days_ago', 7)
                end_time = datetime.now()
                start_time = end_time - timedelta(days=days_ago)
                query_params['time_range'] = (start_time, end_time)

            query = MemoryQuery(
                query_type=query_type,
                parameters=query_params
            )

            # æ¢å¤è®°å¿†
            result = await self.memory_system.recover_memory(query, project_path)

            return {
                "success": result.success,
                "snapshots_found": len(result.snapshots),
                "confidence": result.confidence,
                "insights": result.insights,
                "suggestions": result.suggestions,
                "snapshots": [
                    {
                        "id": s.id,
                        "timestamp": s.timestamp.isoformat(),
                        "nodes": len(s.graph_data.nodes),
                        "edges": len(s.graph_data.edges)
                    }
                    for s in result.snapshots[:5]  # æœ€å¤šè¿”å›5ä¸ª
                ]
            }

        except Exception as e:
            logger.error(f"æ¢å¤è®°å¿†å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e)
            }

class AnalyzeMemoryTool(MemoryTool):
    """åˆ†æé¡¹ç›®è®°å¿†å·¥å…·"""

    name = "analyze_project_memory"
    description = "åˆ†æé¡¹ç›®çš„æ¼”åŒ–å†å²å’Œè¶‹åŠ¿"

    parameters = {
        "type": "object",
        "properties": {
            "project_path": {
                "type": "string",
                "description": "é¡¹ç›®è·¯å¾„"
            },
            "analysis_type": {
                "type": "string",
                "enum": ["growth", "complexity", "dependencies", "patterns"],
                "description": "åˆ†æç±»å‹"
            },
            "time_range_days": {
                "type": "integer",
                "description": "åˆ†ææ—¶é—´èŒƒå›´(å¤©)"
            }
        },
        "required": ["analysis_type"]
    }

    def __init__(self):
        self.memory_system = ProjectMemorySystem()
        self.assistant = MemoryRecoveryAssistant(self.memory_system)

    async def execute(self, **kwargs) -> Dict[str, Any]:
        """æ‰§è¡Œè®°å¿†åˆ†æ"""
        try:
            project_path = kwargs.get('project_path', os.getcwd())
            analysis_type = kwargs['analysis_type']
            time_range_days = kwargs.get('time_range_days', 30)

            if analysis_type == "growth":
                # åˆ†æå¢é•¿
                time_range = (
                    datetime.now() - timedelta(days=time_range_days),
                    datetime.now()
                )
                growth = await self.assistant.explain_growth(
                    project_path,
                    time_range
                )
                return {
                    "success": True,
                    "analysis_type": "growth",
                    "result": growth
                }

            elif analysis_type == "complexity":
                # åˆ†æå¤æ‚åº¦å˜åŒ–
                snapshots = await self.memory_system.get_recent_snapshots(
                    project_path,
                    limit=10
                )
                complexities = []
                for snapshot in snapshots:
                    avg_complexity = sum(
                        n.complexity for n in snapshot.graph_data.nodes
                    ) / len(snapshot.graph_data.nodes)
                    complexities.append({
                        "timestamp": snapshot.timestamp.isoformat(),
                        "complexity": avg_complexity,
                        "node_count": len(snapshot.graph_data.nodes)
                    })

                return {
                    "success": True,
                    "analysis_type": "complexity",
                    "result": complexities
                }

            elif analysis_type == "dependencies":
                # åˆ†æä¾èµ–å˜åŒ–
                snapshots = await self.memory_system.get_recent_snapshots(
                    project_path,
                    limit=10
                )
                dependencies = []
                for snapshot in snapshots:
                    density = len(snapshot.graph_data.edges) / max(
                        len(snapshot.graph_data.nodes) * (len(snapshot.graph_data.nodes) - 1),
                        1
                    )
                    dependencies.append({
                        "timestamp": snapshot.timestamp.isoformat(),
                        "edge_count": len(snapshot.graph_data.edges),
                        "density": density
                    })

                return {
                    "success": True,
                    "analysis_type": "dependencies",
                    "result": dependencies
                }

            elif analysis_type == "patterns":
                # åˆ†ææ¨¡å¼
                snapshots = await self.memory_system.get_recent_snapshots(
                    project_path,
                    limit=20
                )

                # ç®€å•çš„æ¨¡å¼è¯†åˆ«
                patterns = {
                    "growth_trend": "increasing" if len(snapshots) > 1 and
                                   len(snapshots[0].graph_data.nodes) >
                                   len(snapshots[-1].graph_data.nodes) else "stable",
                    "snapshot_frequency": len(snapshots),
                    "common_triggers": self._analyze_triggers(snapshots)
                }

                return {
                    "success": True,
                    "analysis_type": "patterns",
                    "result": patterns
                }

            else:
                return {
                    "success": False,
                    "error": f"æœªçŸ¥çš„åˆ†æç±»å‹: {analysis_type}"
                }

        except Exception as e:
            logger.error(f"åˆ†æè®°å¿†å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e)
            }

    def _analyze_triggers(self, snapshots: List) -> Dict[str, int]:
        """åˆ†æè§¦å‘å™¨åˆ†å¸ƒ"""
        triggers = {}
        for snapshot in snapshots:
            trigger = snapshot.metadata.get('trigger', 'unknown')
            triggers[trigger] = triggers.get(trigger, 0) + 1
        return triggers

class AutoMemoryMonitor:
    """è‡ªåŠ¨è®°å¿†ç›‘æ§å™¨"""

    def __init__(self, project_path: str):
        self.project_path = project_path
        self.memory_system = ProjectMemorySystem()
        self.monitoring = False
        self.last_snapshot_time = None
        self.file_watcher = None

    async def start_monitoring(
        self,
        interval_minutes: int = 60,
        watch_files: bool = True
    ):
        """å¼€å§‹ç›‘æ§"""
        self.monitoring = True
        logger.info(f"å¼€å§‹ç›‘æ§é¡¹ç›®: {self.project_path}")

        # åˆ›å»ºåˆå§‹å¿«ç…§
        await self.memory_system.create_snapshot(
            self.project_path,
            trigger="monitor_start"
        )
        self.last_snapshot_time = datetime.now()

        # å¯åŠ¨å®šæ—¶å¿«ç…§
        asyncio.create_task(self._periodic_snapshot(interval_minutes))

        # å¯åŠ¨æ–‡ä»¶ç›‘æ§
        if watch_files:
            asyncio.create_task(self._watch_files())

    async def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.monitoring = False
        logger.info("åœæ­¢ç›‘æ§")

        # åˆ›å»ºæœ€ç»ˆå¿«ç…§
        await self.memory_system.create_snapshot(
            self.project_path,
            trigger="monitor_stop"
        )

    async def _periodic_snapshot(self, interval_minutes: int):
        """å®šæœŸå¿«ç…§"""
        while self.monitoring:
            await asyncio.sleep(interval_minutes * 60)
            if self.monitoring:
                await self.memory_system.create_snapshot(
                    self.project_path,
                    trigger="periodic"
                )
                self.last_snapshot_time = datetime.now()
                logger.info("åˆ›å»ºå®šæœŸå¿«ç…§")

    async def _watch_files(self):
        """ç›‘æ§æ–‡ä»¶å˜åŒ–"""
        # ç®€åŒ–ç‰ˆæ–‡ä»¶ç›‘æ§
        last_check = {}

        while self.monitoring:
            await asyncio.sleep(30)  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡

            changed_files = []
            for root, dirs, files in os.walk(self.project_path):
                # è·³è¿‡ç‰¹å®šç›®å½•
                if any(skip in root for skip in ['.git', '__pycache__', 'node_modules']):
                    continue

                for file in files:
                    if file.endswith(('.py', '.js', '.ts', '.java')):
                        file_path = os.path.join(root, file)
                        try:
                            mtime = os.path.getmtime(file_path)
                            if file_path in last_check:
                                if mtime > last_check[file_path]:
                                    changed_files.append(file_path)
                            last_check[file_path] = mtime
                        except Exception:
                            pass

            # å¦‚æœæœ‰å¤§é‡æ–‡ä»¶å˜åŒ–ï¼Œåˆ›å»ºå¿«ç…§
            if len(changed_files) > 10:
                logger.info(f"æ£€æµ‹åˆ° {len(changed_files)} ä¸ªæ–‡ä»¶å˜åŒ–ï¼Œåˆ›å»ºå¿«ç…§")
                await self.memory_system.create_snapshot(
                    self.project_path,
                    trigger="file_changes",
                    context={"changed_files": changed_files[:20]}  # æœ€å¤šè®°å½•20ä¸ª
                )
                self.last_snapshot_time = datetime.now()

# ============================================
# Gité›†æˆ
# ============================================

class GitMemoryIntegration:
    """Gité’©å­é›†æˆ - è‡ªåŠ¨åœ¨æäº¤æ—¶ä¿å­˜è®°å¿†"""

    @staticmethod
    def create_git_hooks(project_path: str):
        """åˆ›å»ºGité’©å­"""
        hooks_dir = Path(project_path) / ".git" / "hooks"
        if not hooks_dir.exists():
            logger.error("ä¸æ˜¯Gitä»“åº“")
            return False

        # åˆ›å»ºpost-commité’©å­
        post_commit_hook = hooks_dir / "post-commit"
        hook_content = """#!/bin/bash
# MCPè®°å¿†ç³»ç»Ÿ - è‡ªåŠ¨ä¿å­˜æäº¤å¿«ç…§

python3 -c "
import asyncio
from src.mcp_tools.memory_tools import SaveMemoryTool

async def save():
    tool = SaveMemoryTool()
    result = await tool.execute(
        trigger='commit',
        message='Git commit snapshot'
    )
    print(f'è®°å¿†å¿«ç…§å·²ä¿å­˜: {result.get(\"snapshot_id\")}')

asyncio.run(save())
" 2>/dev/null || true
"""

        with open(post_commit_hook, 'w') as f:
            f.write(hook_content)

        # è®¾ç½®æ‰§è¡Œæƒé™
        os.chmod(post_commit_hook, 0o755)

        logger.info("Gité’©å­å·²åˆ›å»º")
        return True

# ============================================
# æ³¨å†Œå·¥å…·åˆ°MCP
# ============================================

def register_memory_tools():
    """æ³¨å†Œè®°å¿†å·¥å…·åˆ°MCP"""
    return [
        SaveMemoryTool(),
        RecoverMemoryTool(),
        AnalyzeMemoryTool()
    ]

# ============================================
# æµ‹è¯•å’Œæ¼”ç¤º
# ============================================

async def demo():
    """æ¼”ç¤ºè®°å¿†å·¥å…·çš„ä½¿ç”¨"""
    print("=" * 60)
    print("ğŸ§  MCPè®°å¿†å·¥å…·æ¼”ç¤º")
    print("=" * 60)

    # 1. ä¿å­˜è®°å¿†
    print("\n1. ä¿å­˜é¡¹ç›®è®°å¿†...")
    save_tool = SaveMemoryTool()
    result = await save_tool.execute(
        project_path="/Users/mac/Downloads/MCP",
        trigger="demo",
        message="æ¼”ç¤ºè®°å¿†ä¿å­˜"
    )
    print(f"   ç»“æœ: {result}")

    # 2. æ¢å¤è®°å¿†
    print("\n2. æ¢å¤é¡¹ç›®è®°å¿†...")
    recover_tool = RecoverMemoryTool()
    result = await recover_tool.execute(
        project_path="/Users/mac/Downloads/MCP",
        query_type="similarity"
    )
    print(f"   æ‰¾åˆ°å¿«ç…§: {result.get('snapshots_found')}")
    print(f"   ç½®ä¿¡åº¦: {result.get('confidence')}")

    # 3. åˆ†æè®°å¿†
    print("\n3. åˆ†æé¡¹ç›®è®°å¿†...")
    analyze_tool = AnalyzeMemoryTool()
    result = await analyze_tool.execute(
        project_path="/Users/mac/Downloads/MCP",
        analysis_type="complexity"
    )
    print(f"   åˆ†æç»“æœ: {result.get('result')}")

    # 4. è‡ªåŠ¨ç›‘æ§
    print("\n4. å¯åŠ¨è‡ªåŠ¨ç›‘æ§...")
    monitor = AutoMemoryMonitor("/Users/mac/Downloads/MCP")
    await monitor.start_monitoring(interval_minutes=60, watch_files=False)
    print("   âœ… ç›‘æ§å·²å¯åŠ¨")

    # ç­‰å¾…å‡ ç§’ååœæ­¢
    await asyncio.sleep(3)
    await monitor.stop_monitoring()
    print("   âœ… ç›‘æ§å·²åœæ­¢")

    print("\n" + "=" * 60)
    print("ğŸ’¡ MCPè®°å¿†å·¥å…·åŠŸèƒ½:")
    print("   1. save_project_memory - ä¿å­˜è®°å¿†å¿«ç…§")
    print("   2. recover_project_memory - æ¢å¤å†å²è®°å¿†")
    print("   3. analyze_project_memory - åˆ†ææ¼”åŒ–è¶‹åŠ¿")
    print("   4. è‡ªåŠ¨ç›‘æ§å’ŒGité›†æˆ")
    print("=" * 60)

if __name__ == "__main__":
    asyncio.run(demo())