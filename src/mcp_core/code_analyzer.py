#!/usr/bin/env python3
"""
ä»£ç çŸ¥è¯†å›¾è°± - ä»£ç åˆ†æå¼•æ“

æ·±åº¦åˆ†æPythoné¡¹ç›®ï¼Œæå–ç»“æ„åŒ–çŸ¥è¯†ï¼Œæ„å»ºæ°¸ä¹…è®°å¿†
"""

import ast
import os
import json
from pathlib import Path
from typing import Dict, List, Set, Any, Optional
from dataclasses import dataclass, asdict
from collections import defaultdict
import hashlib
import logging

# Configure logger
logger = logging.getLogger(__name__)


@dataclass
class CodeEntity:
    """ä»£ç å®ä½“"""
    id: str  # å”¯ä¸€æ ‡è¯†
    type: str  # ç±»å‹: class, function, variable, module
    name: str  # åç§°
    qualified_name: str  # å®Œå…¨é™å®šå
    file_path: str  # æ–‡ä»¶è·¯å¾„
    line_number: int  # è¡Œå·
    end_line: int  # ç»“æŸè¡Œå·
    docstring: Optional[str] = None  # æ–‡æ¡£å­—ç¬¦ä¸²
    signature: Optional[str] = None  # å‡½æ•°ç­¾å
    parent_id: Optional[str] = None  # çˆ¶å®ä½“ID
    metadata: Dict[str, Any] = None  # é¢å¤–å…ƒæ•°æ®

    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}


@dataclass
class CodeRelation:
    """ä»£ç å…³ç³»"""
    source_id: str  # æºå®ä½“ID
    target_id: str  # ç›®æ ‡å®ä½“ID
    relation_type: str  # å…³ç³»ç±»å‹: calls, imports, inherits, uses
    metadata: Dict[str, Any] = None  # é¢å¤–å…ƒæ•°æ®

    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}


class PythonCodeAnalyzer(ast.NodeVisitor):
    """Pythonä»£ç ASTåˆ†æå™¨"""

    def __init__(self, file_path: str, project_root: str):
        self.file_path = file_path
        self.project_root = project_root
        self.relative_path = os.path.relpath(file_path, project_root)

        # å®ä½“å­˜å‚¨
        self.entities: List[CodeEntity] = []
        self.relations: List[CodeRelation] = []

        # ä¸Šä¸‹æ–‡æ ˆ
        self.context_stack: List[str] = []  # å½“å‰ä½œç”¨åŸŸ
        self.current_class: Optional[str] = None

        # æ˜ å°„è¡¨
        self.entity_map: Dict[str, CodeEntity] = {}  # name -> entity

    def analyze(self, source_code: str) -> tuple[List[CodeEntity], List[CodeRelation]]:
        """åˆ†ææºä»£ç """
        try:
            tree = ast.parse(source_code, filename=self.file_path)
            self.visit(tree)
            return self.entities, self.relations
        except SyntaxError as e:
            logger.info(f"âš ï¸  è¯­æ³•é”™è¯¯ {self.file_path}: {e}")
            return [], []

    def _generate_id(self, type: str, name: str, line: int) -> str:
        """ç”Ÿæˆå”¯ä¸€ID"""
        key = f"{self.relative_path}:{type}:{name}:{line}"
        return hashlib.md5(key.encode()).hexdigest()[:16]

    def _get_qualified_name(self, name: str) -> str:
        """è·å–å®Œå…¨é™å®šå"""
        if self.context_stack:
            return ".".join(self.context_stack + [name])
        return name

    def _get_docstring(self, node) -> Optional[str]:
        """æå–æ–‡æ¡£å­—ç¬¦ä¸²"""
        return ast.get_docstring(node)

    # ==================== è®¿é—®è€…æ¨¡å¼ ====================

    def visit_ClassDef(self, node: ast.ClassDef):
        """è®¿é—®ç±»å®šä¹‰"""
        qualified_name = self._get_qualified_name(node.name)
        entity_id = self._generate_id("class", node.name, node.lineno)

        # åˆ›å»ºç±»å®ä½“
        entity = CodeEntity(
            id=entity_id,
            type="class",
            name=node.name,
            qualified_name=qualified_name,
            file_path=self.relative_path,
            line_number=node.lineno,
            end_line=getattr(node, 'end_lineno', node.lineno),
            docstring=self._get_docstring(node),
            metadata={
                "bases": [self._get_name(base) for base in node.bases],
                "decorators": [self._get_name(dec) for dec in node.decorator_list],
                "methods": [],
                "attributes": []
            }
        )

        self.entities.append(entity)
        self.entity_map[qualified_name] = entity

        # ç»§æ‰¿å…³ç³»
        for base in node.bases:
            base_name = self._get_name(base)
            if base_name:
                self.relations.append(CodeRelation(
                    source_id=entity_id,
                    target_id=base_name,  # å…ˆå­˜åå­—ï¼Œåç»­è§£æ
                    relation_type="inherits",
                    metadata={"base_class": base_name}
                ))

        # è¿›å…¥ç±»ä½œç”¨åŸŸ
        old_class = self.current_class
        self.current_class = entity_id
        self.context_stack.append(node.name)

        self.generic_visit(node)

        # é€€å‡ºç±»ä½œç”¨åŸŸ
        self.context_stack.pop()
        self.current_class = old_class

    def visit_FunctionDef(self, node: ast.FunctionDef):
        """è®¿é—®å‡½æ•°/æ–¹æ³•å®šä¹‰"""
        qualified_name = self._get_qualified_name(node.name)
        entity_id = self._generate_id("function", node.name, node.lineno)

        # æå–å‚æ•°
        args = []
        for arg in node.args.args:
            arg_name = arg.arg
            arg_type = None
            if arg.annotation:
                arg_type = ast.unparse(arg.annotation)
            args.append({"name": arg_name, "type": arg_type})

        # æå–è¿”å›ç±»å‹
        return_type = None
        if node.returns:
            return_type = ast.unparse(node.returns)

        # ç”Ÿæˆå‡½æ•°ç­¾å
        signature = self._generate_signature(node.name, args, return_type)

        # åˆ›å»ºå‡½æ•°å®ä½“
        entity = CodeEntity(
            id=entity_id,
            type="function" if not self.current_class else "method",
            name=node.name,
            qualified_name=qualified_name,
            file_path=self.relative_path,
            line_number=node.lineno,
            end_line=getattr(node, 'end_lineno', node.lineno),
            docstring=self._get_docstring(node),
            signature=signature,
            parent_id=self.current_class,
            metadata={
                "arguments": args,
                "return_type": return_type,
                "decorators": [self._get_name(dec) for dec in node.decorator_list],
                "is_async": isinstance(node, ast.AsyncFunctionDef),
                "calls": [],  # è°ƒç”¨çš„å‡½æ•°
                "uses": []    # ä½¿ç”¨çš„å˜é‡/ç±»
            }
        )

        self.entities.append(entity)
        self.entity_map[qualified_name] = entity

        # å¦‚æœæ˜¯ç±»æ–¹æ³•ï¼Œå»ºç«‹çˆ¶å­å…³ç³»
        if self.current_class:
            self.relations.append(CodeRelation(
                source_id=self.current_class,
                target_id=entity_id,
                relation_type="contains",
                metadata={"type": "method"}
            ))

        # è¿›å…¥å‡½æ•°ä½œç”¨åŸŸ
        self.context_stack.append(node.name)

        # åˆ†æå‡½æ•°ä½“
        self._analyze_function_body(node, entity_id)

        # é€€å‡ºå‡½æ•°ä½œç”¨åŸŸ
        self.context_stack.pop()

    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):
        """è®¿é—®å¼‚æ­¥å‡½æ•°"""
        self.visit_FunctionDef(node)

    def visit_Import(self, node: ast.Import):
        """è®¿é—®importè¯­å¥"""
        for alias in node.names:
            module_name = alias.name
            # è®°å½•å¯¼å…¥å…³ç³»
            # TODO: åˆ›å»ºæ¨¡å—å®ä½“å’Œå¯¼å…¥å…³ç³»

    def visit_ImportFrom(self, node: ast.ImportFrom):
        """è®¿é—®from...importè¯­å¥"""
        module_name = node.module if node.module else ""
        for alias in node.names:
            name = alias.name
            # è®°å½•å¯¼å…¥å…³ç³»
            # TODO: åˆ›å»ºå¯¼å…¥å…³ç³»

    # ==================== è¾…åŠ©æ–¹æ³• ====================

    def _analyze_function_body(self, func_node, func_id: str):
        """åˆ†æå‡½æ•°ä½“ï¼Œæå–è°ƒç”¨å…³ç³»"""
        for node in ast.walk(func_node):
            # å‡½æ•°è°ƒç”¨
            if isinstance(node, ast.Call):
                func_name = self._get_name(node.func)
                if func_name:
                    self.relations.append(CodeRelation(
                        source_id=func_id,
                        target_id=func_name,  # å…ˆå­˜åå­—
                        relation_type="calls",
                        metadata={"function": func_name}
                    ))

            # å±æ€§è®¿é—® (å¯èƒ½æ˜¯æ–¹æ³•è°ƒç”¨)
            elif isinstance(node, ast.Attribute):
                attr_name = node.attr
                # TODO: åˆ†æå±æ€§è®¿é—®

    def _get_name(self, node) -> Optional[str]:
        """ä»ASTèŠ‚ç‚¹è·å–åç§°"""
        if isinstance(node, ast.Name):
            return node.id
        elif isinstance(node, ast.Attribute):
            return ast.unparse(node)
        elif isinstance(node, ast.Call):
            return self._get_name(node.func)
        else:
            try:
                return ast.unparse(node)
            except Exception as e:
                return None

    def _generate_signature(self, name: str, args: List[Dict], return_type: Optional[str]) -> str:
        """ç”Ÿæˆå‡½æ•°ç­¾å"""
        arg_strs = []
        for arg in args:
            if arg.get("type"):
                arg_strs.append(f"{arg['name']}: {arg['type']}")
            else:
                arg_strs.append(arg['name'])

        signature = f"{name}({', '.join(arg_strs)})"
        if return_type:
            signature += f" -> {return_type}"

        return signature


class ProjectAnalyzer:
    """é¡¹ç›®çº§åˆ«åˆ†æå™¨"""

    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.all_entities: List[CodeEntity] = []
        self.all_relations: List[CodeRelation] = []

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_files": 0,
            "total_lines": 0,
            "total_classes": 0,
            "total_functions": 0,
            "total_imports": 0,
            "total_relations": 0
        }

    def analyze_project(self, extensions: List[str] = [".py"]) -> Dict[str, Any]:
        """åˆ†ææ•´ä¸ªé¡¹ç›®"""
        logger.info(f"ğŸ“Š å¼€å§‹åˆ†æé¡¹ç›®: {self.project_root}")

        # æ‰«ææ‰€æœ‰Pythonæ–‡ä»¶
        python_files = []
        for ext in extensions:
            python_files.extend(self.project_root.rglob(f"*{ext}"))

        # è¿‡æ»¤æ‰è™šæ‹Ÿç¯å¢ƒå’Œç¼“å­˜
        python_files = [
            f for f in python_files
            if not any(part in f.parts for part in ['venv', '__pycache__', '.git', 'node_modules'])
        ]

        self.stats["total_files"] = len(python_files)

        logger.info(f"ğŸ“‚ æ‰¾åˆ° {len(python_files)} ä¸ªPythonæ–‡ä»¶")

        # é€ä¸ªåˆ†ææ–‡ä»¶
        for i, file_path in enumerate(python_files, 1):
            logger.info(f"[{i}/{len(python_files)}] åˆ†æ: {file_path.relative_to(self.project_root)}")
            self._analyze_file(str(file_path))

        # åå¤„ç†ï¼šè§£æå…³ç³»ä¸­çš„åå­—å¼•ç”¨
        self._resolve_references()

        # æ›´æ–°ç»Ÿè®¡
        self.stats["total_classes"] = sum(1 for e in self.all_entities if e.type == "class")
        self.stats["total_functions"] = sum(1 for e in self.all_entities if e.type in ["function", "method"])
        self.stats["total_relations"] = len(self.all_relations)

        logger.info("\n" + "="*60)
        logger.info("âœ… åˆ†æå®Œæˆï¼")
        logger.info(f"   æ–‡ä»¶æ•°: {self.stats['total_files']}")
        logger.info(f"   ç±»æ•°é‡: {self.stats['total_classes']}")
        logger.info(f"   å‡½æ•°æ•°: {self.stats['total_functions']}")
        logger.info(f"   å…³ç³»æ•°: {self.stats['total_relations']}")
        logger.info("="*60)

        return {
            "entities": [asdict(e) for e in self.all_entities],
            "relations": [asdict(r) for r in self.all_relations],
            "stats": self.stats
        }

    def _analyze_file(self, file_path: str):
        """åˆ†æå•ä¸ªæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                source_code = f.read()
                self.stats["total_lines"] += len(source_code.splitlines())

            analyzer = PythonCodeAnalyzer(file_path, str(self.project_root))
            entities, relations = analyzer.analyze(source_code)

            self.all_entities.extend(entities)
            self.all_relations.extend(relations)

        except Exception as e:
            logger.info(f"  âš ï¸  é”™è¯¯: {e}")

    def _resolve_references(self):
        """è§£æå…³ç³»ä¸­çš„åå­—å¼•ç”¨ä¸ºå®é™…ID"""
        # æ„å»ºåå­—->IDæ˜ å°„
        name_to_id = {}
        for entity in self.all_entities:
            name_to_id[entity.qualified_name] = entity.id
            name_to_id[entity.name] = entity.id  # ç®€çŸ­åå­—ä¹Ÿæ˜ å°„

        # æ›´æ–°å…³ç³»ä¸­çš„target_id
        for relation in self.all_relations:
            if relation.target_id in name_to_id:
                relation.target_id = name_to_id[relation.target_id]

    def export_json(self, output_path: str):
        """å¯¼å‡ºä¸ºJSON"""
        data = {
            "entities": [asdict(e) for e in self.all_entities],
            "relations": [asdict(r) for r in self.all_relations],
            "stats": self.stats
        }

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        logger.info(f"ğŸ’¾ å¯¼å‡ºåˆ°: {output_path}")

    def generate_graph_summary(self) -> str:
        """ç”Ÿæˆå›¾è°±æ‘˜è¦"""
        summary = []
        summary.append("# ä»£ç çŸ¥è¯†å›¾è°±æ‘˜è¦\n")
        summary.append(f"**é¡¹ç›®**: {self.project_root.name}\n")
        summary.append(f"**æ–‡ä»¶æ•°**: {self.stats['total_files']}\n")
        summary.append(f"**ä»£ç è¡Œ**: {self.stats['total_lines']}\n\n")

        summary.append("## å®ä½“ç»Ÿè®¡\n")
        summary.append(f"- ç±»: {self.stats['total_classes']}\n")
        summary.append(f"- å‡½æ•°/æ–¹æ³•: {self.stats['total_functions']}\n\n")

        summary.append("## ä¸»è¦æ¨¡å—\n")
        # æŒ‰æ–‡ä»¶è·¯å¾„åˆ†ç»„
        files = set(e.file_path for e in self.all_entities)
        for file in sorted(files)[:10]:  # å‰10ä¸ªæ–‡ä»¶
            entities_in_file = [e for e in self.all_entities if e.file_path == file]
            summary.append(f"- `{file}`: {len(entities_in_file)} ä¸ªå®ä½“\n")

        return "".join(summary)


# ==================== æµ‹è¯•ä»£ç  ====================

def main():
    """æµ‹è¯•ä¸»å‡½æ•°"""
    import sys

    if len(sys.argv) < 2:
        logger.info("ç”¨æ³•: python code_analyzer.py <project_path>")
        logger.info("ç¤ºä¾‹: python code_analyzer.py /Users/mac/Downloads/MCP")
        sys.exit(1)

    project_path = sys.argv[1]

    # åˆ›å»ºåˆ†æå™¨
    analyzer = ProjectAnalyzer(project_path)

    # åˆ†æé¡¹ç›®
    result = analyzer.analyze_project()

    # å¯¼å‡ºJSON
    output_path = Path(project_path) / "code_knowledge_graph.json"
    analyzer.export_json(str(output_path))

    # ç”Ÿæˆæ‘˜è¦
    summary = analyzer.generate_graph_summary()
    logger.info("\n" + summary)

    summary_path = Path(project_path) / "code_analysis_summary.md"
    with open(summary_path, 'w', encoding='utf-8') as f:
        f.write(summary)
    logger.info(f"ğŸ“„ æ‘˜è¦ä¿å­˜åˆ°: {summary_path}")


if __name__ == "__main__":
    main()
